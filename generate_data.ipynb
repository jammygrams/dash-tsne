{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',  remove=('headers', 'footers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts\n",
      "data shape: (2933,)\n",
      "comp.graphics: 584\n",
      "rec.sport.baseball: 594\n",
      "talk.politics.mideast: 597\n",
      "rec.autos: 594\n",
      "sci.med: 564\n"
     ]
    }
   ],
   "source": [
    "target_names = ['comp.graphics', 'rec.sport.baseball', 'talk.politics.mideast', 'rec.autos', 'sci.med']\n",
    "target_nums = [i for i in range(20) if newsgroups_train.target_names[i] in target_names]\n",
    "\n",
    "masks = [newsgroups_train.target == i for i in target_nums]\n",
    "mask = np.array([any(tup) for tup in zip(*masks)])\n",
    "\n",
    "data = np.array(newsgroups_train.data)[mask]\n",
    "targets = np.array(newsgroups_train.target)[mask]\n",
    "\n",
    "print(f'Counts\\ndata shape: {data.shape}')\n",
    "# print(f'targets shape: {targets.shape}')\n",
    "\n",
    "for name, count in zip(target_names, [np.sum(m) for m in masks]):\n",
    "    print(f'{name}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in data/tfidf_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def save_labels(name:string):\n",
    "    PATH = f'data/{name}_labels.csv'\n",
    "    # first row is header\n",
    "    labels = ['header'] + [newsgroups_train.target_names[i] for i in targets]\n",
    "    with open(PATH, 'w') as myfile:\n",
    "        wr = csv.writer(myfile,dialect='excel')\n",
    "        for row in labels:\n",
    "            wr.writerow([row])\n",
    "    print(f'Saved in {PATH}')\n",
    "    \n",
    "save_labels('tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Robert J.C. Kyanko (rob@rjck.UUCP) wrote:\\n> abraxis@iastate.edu writes in article <abraxis.734340159@class1.iastate.edu>:\\n> > Anyone know about the Weitek P9000 graphics chip?\\n> As far as the low-level stuff goes, it looks pretty nice.  It's got this\\n> quadrilateral fill command that requires just the four points.\\n\\nDo you have Weitek's address/phone number?  I'd like to get some information\\nabout this chip.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert J.C. Kyanko (rob@rjck.UUCP) wrote:\n",
      "> abraxis@iastate.edu writes in article <abraxis.734340159@class1.iastate.edu>:\n",
      "> > Anyone know about the Weitek P9000 graphics chip?\n",
      "> As far as the low-level stuff goes, it looks pretty nice.  It's got this\n",
      "> quadrilateral fill command that requires just the four points.\n",
      "\n",
      "Do you have Weitek's address/phone number?  I'd like to get some information\n",
      "about this chip.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.DataFrame(data)\n",
    "text.to_pickle('data/source_text.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.56 s, sys: 70.9 ms, total: 2.63 s\n",
      "Wall time: 2.67 s\n",
      "\n",
      "Vocab size: 60109\n",
      "Document vector shape: (2933, 60109)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "\n",
    "# vectorize\n",
    "bow_vec = TfidfVectorizer(max_df=0.25, min_df=0.001, ngram_range=(1, 2),\n",
    "                          sublinear_tf=True, use_idf=True)\n",
    "%time doc_bow = bow_vec.fit_transform(data)\n",
    "\n",
    "# get vocab\n",
    "vocab = bow_vec.get_feature_names()\n",
    "print('\\nVocab size:', len(vocab))\n",
    "print('Document vector shape:', doc_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     \t% Docs\n",
      "==============================\n",
      "these     \t19.16\n",
      "that the  \t19.77\n",
      "could     \t19.98\n",
      "for the   \t20.08\n",
      "time      \t20.12\n",
      "them      \t20.76\n",
      "people    \t21.00\n",
      "had       \t21.41\n",
      "does      \t21.55\n",
      "than      \t21.79\n",
      "com       \t21.79\n",
      "we        \t21.85\n",
      "to be     \t22.37\n",
      "were      \t22.74\n",
      "their     \t22.81\n",
      "also      \t23.05\n",
      "he        \t23.18\n",
      "only      \t23.32\n",
      "get       \t23.59\n",
      "other     \t23.63\n",
      "how       \t23.66\n",
      "been      \t23.66\n",
      "when      \t23.90\n",
      "think     \t24.21\n",
      "it is     \t24.96\n"
     ]
    }
   ],
   "source": [
    "counts = np.count_nonzero(doc_bow.toarray(), axis=0)\n",
    "percentage = 100 * counts / len(data)\n",
    "print('Token'.ljust(10), '% Docs', sep='\\t')\n",
    "print('='*30)\n",
    "for idx in np.argsort(counts)[-25:]:\n",
    "    print(vocab[idx].ljust(10), f'{percentage[idx]:.2f}', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/decomposition.html\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "svd = TruncatedSVD(n_components=200, n_iter=7, random_state=42)\n",
    "%time doc_bow_svd = svd.fit_transform(doc_bow) \n",
    "\n",
    "print('explained variance:', svd.explained_variance_ratio_.sum())\n",
    "\n",
    "\n",
    "PCA = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in data/tfidf_input.csv\n"
     ]
    }
   ],
   "source": [
    "def save_vectors(vectors, name:string):\n",
    "    PATH = f\"data/{name}_input.csv\"\n",
    "    # create .csv header\n",
    "    head_vals = np.arange(vectors.shape[1])\n",
    "    header = \",\".join([item for item in head_vals.astype(str)])\n",
    "    np.savetxt(PATH, vectors, header=header, comments='', delimiter=',')\n",
    "    print(f'Saved in {PATH}')\n",
    "\n",
    "save_vectors(doc_bow_svd, 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out high d object\n",
    "# TODO: TOO BIG\n",
    "# head_vals = np.arange(doc_bow_svd.shape[1])\n",
    "# header = \",\".join([item for item in head_vals.astype(str)])\n",
    "\n",
    "# np.savetxt(\"data/tfidf_input.csv\", doc_bow_svd, header=header, comments='', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nus/miniconda3/envs/tsne-vis-env/lib/python3.6/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# tokenize\n",
    "def read_corpus(data, tokens_only=False):\n",
    "    for i, doc in enumerate(data):\n",
    "        if tokens_only:\n",
    "            yield gensim.utils.simple_preprocess(doc)\n",
    "        else:\n",
    "            yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(doc), [i])\n",
    "        \n",
    "corpus = list(read_corpus(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab length: 20979\n",
      "sample tokenised doc:\n",
      "TaggedDocument(['was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail'], [0])\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=200, min_count=2, epochs=40)\n",
    "model.build_vocab(corpus)\n",
    "\n",
    "print(f'vocab length: {len(model.wv.vocab)}')\n",
    "print(f'sample tokenised doc:\\n{corpus[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.4 s, sys: 1.64 s, total: 59.1 s\n",
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "%time model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.78%\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(corpus)):\n",
    "    inferred_vector = model.infer_vector(corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    # what rank is the trained vector in order of sim to inferred vector\n",
    "    rank = [docid for docid, sim in sims].index(doc_id) \n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])\n",
    "\n",
    "print(f'{100* np.sum([r==0 for r in ranks]) / len(ranks):.2f}%')\n",
    "\n",
    "# import collections\n",
    "# counter = collections.Counter(ranks)\n",
    "# sorted(counter.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (2932): «in article qkgbuinns shelley washington edu bolson carson washington edu edward bolson writes boy this will be embarassing if it is trivial or an faq given points non coplanar how does one find the sphere that is center and radius exactly fitting those points know how to do it for circle from points but do not immediately see straightforward way to do it in have checked some geometry books graphics gems and farin but am still at loss please have mercy on me and provide the solution wouldn this require hyper sphere in space points over specifies sphere as far as can see unless that is you can prove that point exists in space that is equi distant from the points and this may not necessarily happen correct me if wrong which quite possibly am steve»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d200,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (2657, 0.8543505668640137): «in article rb srgenprp sr hp com almanb sr hp com bob alman writes hose»\n",
      "\n",
      "SECOND-MOST (735, 0.849534273147583): «just kidding»\n",
      "\n",
      "MEDIAN (533, 0.46986547112464905): «in randall moose randall informix com randall rhea writes the royals are darkness they are the void of our time when they play shame descends upon the land like cold front from canada they are humiliation to all who have lived and all who shall ever live they are utterly and completely doomed other than that guess they re ok oh lighten up what depresses me is that they might actually finish last which believe hasn happened since their second season in never mind that gubizca is with era gardner at our main recent acquisitions lind mcreynolds jose are averaging david cone is about how he was doing in kc before joining the mets several years ago our hitting sucks and our pitching has collapsed and we ve won one game at home they ve won more games in their first ten games than last year and brian mcrae is actually batting over the mendoza line»\n",
      "\n",
      "LEAST (2085, -0.1267537921667099): «»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in data/doc2vec_input.csv\n",
      "Saved in data/doc2vec_labels.csv\n"
     ]
    }
   ],
   "source": [
    "save_vectors(model.docvecs.vectors_docs, 'doc2vec')\n",
    "save_labels('doc2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_text = list(text.strip() for text in data)\n",
    "bert_text = ['BLANK' if text is '' else text for text in bert_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server config:\n",
      "                        client\t=\t4d940469-5918-4f4d-8a1c-b068b8938f87\n",
      "                   num_process\t=\t2                             \n",
      "          ventilator -> worker\t=\t['ipc://tmpRytRC8/socket', 'ipc://tmpORskFY/socket', 'ipc://tmpZc9NHO/socket', 'ipc://tmp2RmiKE/socket', 'ipc://tmpmZaNMu/socket', 'ipc://tmpmaiiPk/socket', 'ipc://tmpfsXNRa/socket', 'ipc://tmp4t9jU0/socket']\n",
      "                worker -> sink\t=\tipc://tmpSpUOnf/socket        \n",
      "           ventilator <-> sink\t=\tipc://tmpq32oAi/socket        \n",
      "           server_current_time\t=\t2019-04-25 10:12:00.033451    \n",
      "                     statistic\t=\t{'num_data_request': 0, 'num_total_seq': 0, 'num_sys_request': 1, 'num_total_request': 1, 'num_total_client': 1, 'num_active_client': 0, 'avg_request_per_client': 1.0, 'min_request_per_client': 1, 'max_request_per_client': 1, 'num_min_request_per_client': 1, 'num_max_request_per_client': 1}\n",
      "                    device_map\t=\t[]                            \n",
      "         num_concurrent_socket\t=\t8                             \n",
      "                     ckpt_name\t=\tbert_model.ckpt               \n",
      "                   config_name\t=\tbert_config.json              \n",
      "                          cors\t=\t*                             \n",
      "                           cpu\t=\tFalse                         \n",
      "            fixed_embed_length\t=\tFalse                         \n",
      "                          fp16\t=\tFalse                         \n",
      "           gpu_memory_fraction\t=\t0.5                           \n",
      "                 graph_tmp_dir\t=\tNone                          \n",
      "              http_max_connect\t=\t10                            \n",
      "                     http_port\t=\tNone                          \n",
      "                  mask_cls_sep\t=\tFalse                         \n",
      "                max_batch_size\t=\t256                           \n",
      "                   max_seq_len\t=\t250                           \n",
      "                     model_dir\t=\t/home/jhamat/models/BERT/cased_L-12_H-768_A-12/\n",
      "                    num_worker\t=\t1                             \n",
      "                 pooling_layer\t=\t[-2]                          \n",
      "              pooling_strategy\t=\t2                             \n",
      "                          port\t=\t5555                          \n",
      "                      port_out\t=\t5556                          \n",
      "                 prefetch_size\t=\t10                            \n",
      "           priority_batch_size\t=\t16                            \n",
      "         show_tokens_to_client\t=\tFalse                         \n",
      "               tuned_model_dir\t=\tNone                          \n",
      "                       verbose\t=\tFalse                         \n",
      "                           xla\t=\tFalse                         \n",
      "            tensorflow_version\t=\t['1', '12', '0']              \n",
      "                python_version\t=\t3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 19:16:44) \n",
      "[GCC 7.3.0]\n",
      "                server_version\t=\t1.8.9                         \n",
      "                 pyzmq_version\t=\t17.1.2                        \n",
      "                   zmq_version\t=\t4.2.5                         \n",
      "             server_start_time\t=\t2019-04-25 10:11:27.631219    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nus/miniconda3/envs/tsne-vis-env/lib/python3.6/site-packages/bert_serving/client/__init__.py:286: UserWarning: some of your sentences have more tokens than \"max_seq_len=250\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 101 ms, sys: 190 ms, total: 291 ms\n",
      "Wall time: 39 s\n"
     ]
    }
   ],
   "source": [
    "from bert_serving.client import BertClient\n",
    "\n",
    "# start server e.g.\n",
    "# bert-serving-start -model_dir ~/models/BERT/cased_L-12_H-768_A-12/ -num_worker=4 -max_seq_len=500\n",
    "\n",
    "bc = BertClient(ip='137.117.67.76', show_server_config=True)\n",
    "%time bert_vectors = bc.encode(bert_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in data/bert_250_word_mean_input.csv\n",
      "Saved in data/bert_250_word_mean_labels.csv\n"
     ]
    }
   ],
   "source": [
    "save_vectors(bert_vectors, 'bert_250_word_mean')\n",
    "save_labels('bert_250_word_mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out new tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 3.08 s, total: 1min 18s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "import bhtsne\n",
    "\n",
    "%time output = bhtsne.tsne(doc_bow_svd, dimensions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 31s, sys: 5.3 s, total: 2min 36s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=3)\n",
    "%time output_2 = tsne.fit_transform(doc_bow_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.loadtxt(\"data/tfidf_input.csv\", skiprows=1)\n",
    "# embedding_array = bhtsne.run_bh_tsne(doc_bow_svd, initial_dims=doc_bow_svd.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{25: 25, 100: 100, 'No PCA': 200}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_dim_ls = [25, 100, None]\n",
    "{('No PCA' if i is None else i): (200 if i is None else i) for i in pca_dim_ls}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.149523</td>\n",
       "      <td>35.135636</td>\n",
       "      <td>13.449234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-33.802058</td>\n",
       "      <td>5.057675</td>\n",
       "      <td>15.112783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-12.953371</td>\n",
       "      <td>6.272250</td>\n",
       "      <td>0.888270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.501414</td>\n",
       "      <td>35.272079</td>\n",
       "      <td>4.175327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.045654</td>\n",
       "      <td>-12.163825</td>\n",
       "      <td>-18.475271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-14.902226</td>\n",
       "      <td>13.177760</td>\n",
       "      <td>-3.301088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.797801</td>\n",
       "      <td>-6.008549</td>\n",
       "      <td>-0.298618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.450804</td>\n",
       "      <td>-25.294197</td>\n",
       "      <td>-13.729284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.211734</td>\n",
       "      <td>4.324410</td>\n",
       "      <td>-7.236874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-10.851260</td>\n",
       "      <td>-18.124040</td>\n",
       "      <td>13.533896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.133236</td>\n",
       "      <td>-4.486353</td>\n",
       "      <td>0.189420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.927272</td>\n",
       "      <td>-6.310285</td>\n",
       "      <td>3.737172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22.016058</td>\n",
       "      <td>-1.609952</td>\n",
       "      <td>-0.306961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.005808</td>\n",
       "      <td>28.887463</td>\n",
       "      <td>1.667216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-9.912714</td>\n",
       "      <td>-9.953646</td>\n",
       "      <td>36.426369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.240507</td>\n",
       "      <td>-5.071921</td>\n",
       "      <td>-20.616352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-20.607898</td>\n",
       "      <td>3.799005</td>\n",
       "      <td>11.437763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-11.480720</td>\n",
       "      <td>-12.004994</td>\n",
       "      <td>38.380559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33.671520</td>\n",
       "      <td>-6.580837</td>\n",
       "      <td>28.685168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27.117871</td>\n",
       "      <td>34.250913</td>\n",
       "      <td>10.696395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.462359</td>\n",
       "      <td>-6.152225</td>\n",
       "      <td>-20.180156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.272772</td>\n",
       "      <td>19.766740</td>\n",
       "      <td>-2.688213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25.011940</td>\n",
       "      <td>14.166796</td>\n",
       "      <td>2.014351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.049559</td>\n",
       "      <td>24.495671</td>\n",
       "      <td>14.611874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.806425</td>\n",
       "      <td>-6.238166</td>\n",
       "      <td>31.584002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-11.104503</td>\n",
       "      <td>16.826508</td>\n",
       "      <td>2.698563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12.837766</td>\n",
       "      <td>0.289661</td>\n",
       "      <td>30.877111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-25.558220</td>\n",
       "      <td>10.673248</td>\n",
       "      <td>8.867841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.239357</td>\n",
       "      <td>-22.797593</td>\n",
       "      <td>6.037327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-6.419428</td>\n",
       "      <td>38.420869</td>\n",
       "      <td>-21.709047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>20.225869</td>\n",
       "      <td>30.289663</td>\n",
       "      <td>-13.760717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>26.363478</td>\n",
       "      <td>9.605007</td>\n",
       "      <td>-7.602605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>3.510785</td>\n",
       "      <td>22.355546</td>\n",
       "      <td>10.235183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>2.165904</td>\n",
       "      <td>18.027675</td>\n",
       "      <td>6.475701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>3.447315</td>\n",
       "      <td>-11.948927</td>\n",
       "      <td>-8.306962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>26.803828</td>\n",
       "      <td>31.941451</td>\n",
       "      <td>13.204226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>-2.754007</td>\n",
       "      <td>-21.049863</td>\n",
       "      <td>18.983770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>1.131906</td>\n",
       "      <td>-9.820295</td>\n",
       "      <td>-17.363914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>-21.219576</td>\n",
       "      <td>24.881108</td>\n",
       "      <td>-0.725150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>7.882046</td>\n",
       "      <td>-5.640999</td>\n",
       "      <td>-19.644964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>5.937375</td>\n",
       "      <td>7.447533</td>\n",
       "      <td>9.449458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>-6.881814</td>\n",
       "      <td>16.250157</td>\n",
       "      <td>-17.105516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>-21.099602</td>\n",
       "      <td>5.564760</td>\n",
       "      <td>-4.492553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>-8.272304</td>\n",
       "      <td>14.381776</td>\n",
       "      <td>-26.134434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>-9.242205</td>\n",
       "      <td>5.023877</td>\n",
       "      <td>-0.526266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>1.626084</td>\n",
       "      <td>-4.964455</td>\n",
       "      <td>21.909399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>5.835656</td>\n",
       "      <td>16.144794</td>\n",
       "      <td>-37.446098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>-5.758136</td>\n",
       "      <td>8.313992</td>\n",
       "      <td>38.762303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>-9.419408</td>\n",
       "      <td>-29.351368</td>\n",
       "      <td>19.118784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>4.296294</td>\n",
       "      <td>-5.141134</td>\n",
       "      <td>-17.058986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>20.482126</td>\n",
       "      <td>-21.683268</td>\n",
       "      <td>-13.092995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>-1.051791</td>\n",
       "      <td>-41.131487</td>\n",
       "      <td>-11.103011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>-28.906699</td>\n",
       "      <td>16.592857</td>\n",
       "      <td>4.011909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>-7.738827</td>\n",
       "      <td>-15.177277</td>\n",
       "      <td>-3.503750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>33.083513</td>\n",
       "      <td>-6.984828</td>\n",
       "      <td>28.894810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>-16.618214</td>\n",
       "      <td>-7.005152</td>\n",
       "      <td>0.998556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>-23.015177</td>\n",
       "      <td>-15.339702</td>\n",
       "      <td>26.733332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>6.521666</td>\n",
       "      <td>-27.077679</td>\n",
       "      <td>25.581610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>6.385392</td>\n",
       "      <td>8.836626</td>\n",
       "      <td>-14.276406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>25.333065</td>\n",
       "      <td>23.239470</td>\n",
       "      <td>6.684462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2933 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x          y          z\n",
       "0     -1.149523  35.135636  13.449234\n",
       "1    -33.802058   5.057675  15.112783\n",
       "2    -12.953371   6.272250   0.888270\n",
       "3      8.501414  35.272079   4.175327\n",
       "4      2.045654 -12.163825 -18.475271\n",
       "5    -14.902226  13.177760  -3.301088\n",
       "6      0.797801  -6.008549  -0.298618\n",
       "7     -0.450804 -25.294197 -13.729284\n",
       "8     12.211734   4.324410  -7.236874\n",
       "9    -10.851260 -18.124040  13.533896\n",
       "10     9.133236  -4.486353   0.189420\n",
       "11    19.927272  -6.310285   3.737172\n",
       "12    22.016058  -1.609952  -0.306961\n",
       "13    11.005808  28.887463   1.667216\n",
       "14    -9.912714  -9.953646  36.426369\n",
       "15     8.240507  -5.071921 -20.616352\n",
       "16   -20.607898   3.799005  11.437763\n",
       "17   -11.480720 -12.004994  38.380559\n",
       "18    33.671520  -6.580837  28.685168\n",
       "19    27.117871  34.250913  10.696395\n",
       "20     2.462359  -6.152225 -20.180156\n",
       "21     5.272772  19.766740  -2.688213\n",
       "22    25.011940  14.166796   2.014351\n",
       "23     0.049559  24.495671  14.611874\n",
       "24     2.806425  -6.238166  31.584002\n",
       "25   -11.104503  16.826508   2.698563\n",
       "26    12.837766   0.289661  30.877111\n",
       "27   -25.558220  10.673248   8.867841\n",
       "28    -1.239357 -22.797593   6.037327\n",
       "29    -6.419428  38.420869 -21.709047\n",
       "...         ...        ...        ...\n",
       "2903  20.225869  30.289663 -13.760717\n",
       "2904  26.363478   9.605007  -7.602605\n",
       "2905   3.510785  22.355546  10.235183\n",
       "2906   2.165904  18.027675   6.475701\n",
       "2907   3.447315 -11.948927  -8.306962\n",
       "2908  26.803828  31.941451  13.204226\n",
       "2909  -2.754007 -21.049863  18.983770\n",
       "2910   1.131906  -9.820295 -17.363914\n",
       "2911 -21.219576  24.881108  -0.725150\n",
       "2912   7.882046  -5.640999 -19.644964\n",
       "2913   5.937375   7.447533   9.449458\n",
       "2914  -6.881814  16.250157 -17.105516\n",
       "2915 -21.099602   5.564760  -4.492553\n",
       "2916  -8.272304  14.381776 -26.134434\n",
       "2917  -9.242205   5.023877  -0.526266\n",
       "2918   1.626084  -4.964455  21.909399\n",
       "2919   5.835656  16.144794 -37.446098\n",
       "2920  -5.758136   8.313992  38.762303\n",
       "2921  -9.419408 -29.351368  19.118784\n",
       "2922   4.296294  -5.141134 -17.058986\n",
       "2923  20.482126 -21.683268 -13.092995\n",
       "2924  -1.051791 -41.131487 -11.103011\n",
       "2925 -28.906699  16.592857   4.011909\n",
       "2926  -7.738827 -15.177277  -3.503750\n",
       "2927  33.083513  -6.984828  28.894810\n",
       "2928 -16.618214  -7.005152   0.998556\n",
       "2929 -23.015177 -15.339702  26.733332\n",
       "2930   6.521666 -27.077679  25.581610\n",
       "2931   6.385392   8.836626 -14.276406\n",
       "2932  25.333065  23.239470   6.684462\n",
       "\n",
       "[2933 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(output, columns=['x', 'y', 'z'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
